# 基于 AMD Radeon AI PRO R9700 的 BEST 实时等离子体计算平台设计

---

**编制日期**: 2026年2月13日  
**文档版本**: V1.0  
**关联文件**: BEST 10MW ECRH 控制保护系统总体设计方案 V2.1

---

## 1. 问题定义：BEST 需要什么样的实时计算能力

### 1.1 核心问题

BEST 托克马克的等离子体控制系统（PCS）和 ECRH 系统各存在一个 **计算瓶颈**，两者串联在同一条控制链上：

```
BEST 实时控制链中的两个计算瓶颈
═══════════════════════════════════════════════════════════════════

诊断信号 → [PCS: EFIT 平衡重建] → [ECRH: 射线追踪] → Launcher 执行
            ↑ 瓶颈 1              ↑ 瓶颈 2
            当前: 5-10 ms (CPU)    当前: 15-20 ms (CPU)
            需要: < 2 ms          需要: < 1 ms

两个瓶颈叠加 → 端到端 ~25 ms → 无法满足快速控制需求
任一瓶颈单独解决都不够 → 必须同时加速
```

| 瓶颈 | 所在系统 | 计算任务 | 当前延迟 | 目标延迟 |
|------|---------|---------|---------|---------|
| **EFIT 平衡重建** | PCS | 诊断信号 → 等离子体磁面结构 ψ(R,Z) | 5-10 ms | < 2 ms |
| **射线追踪** | ECRH | 目标位置 ρ_target → 最优 Launcher 角度 (θ,φ) | 15-20 ms | < 1 ms |

### 1.2 为什么需要实时计算

这两个计算服务于 BEST 的多种运行需求，不仅仅是 NTM 抑制：

| 应用场景 | 需要 EFIT？ | 需要射线追踪？ | 时间尺度 |
|---------|:---:|:---:|---------|
| **等离子体加热优化** | ✓ (确定沉积位置) | ✓ (优化角度) | 秒级（但高分辨率 EFIT 提升精度） |
| **电流驱动维持** | ✓ (q 剖面重建) | ✓ (驱动效率优化) | 百毫秒级 |
| **NTM 抑制** | ✓ (磁岛定位) | ✓ (精确沉积) | **毫秒级**（最苛刻） |
| **等离子体形状控制** | ✓ (边界重建) | — | 毫秒级 |
| **破裂避免** | ✓ (实时监测) | ✓ (快速功率切换) | 毫秒级 |

> **GPU 加速的真正价值**：不是"解决 NTM"，而是为 BEST 提供一个可以实时运行物理模型的通用计算基础设施。NTM 是对该基础设施要求最苛刻的场景。

### 1.3 方案概述：一块 GPU 解决两个瓶颈

本方案的核心思路：在 **一块 AMD Radeon AI PRO R9700 GPU** 上同时运行 GPU-EFIT 和 GPU 射线追踪，通过流水线执行将两个瓶颈一并消除。

---

## 2. 硬件平台：AMD Radeon AI PRO R9700

### 2.1 关键规格

| 参数 | R9700 (RDNA 4, 2025) | 对比: NVIDIA TITAN X (P-EFIT 原始平台, 2016) |
|------|-----|-----|
| **计算单元** | 64 CU, 4096 SP | 28 SM, 3584 CUDA Cores |
| **FP32 算力** | **~48 TFLOPS** | 11 TFLOPS (4.4×) |
| **FP16 矩阵算力** | **191 TFLOPS** | 无 |
| **AI 加速器** | 128 个 (1531 TOPS INT4) | 无 |
| **LDS (专用)** | **128 KB/CU** | 96 KB/SM (与 L1 共享) |
| **寄存器 (VGPR)** | **768 KB/CU** | 256 KB/SM |
| **L3 (Infinity Cache)** | **64 MB** | 无 |
| **显存** | 32 GB GDDR6, 640 GB/s | 12 GB GDDR5X, 480 GB/s |
| **PCIe** | Gen 5 (~64 GB/s) | Gen 3 (~16 GB/s) |
| **编程模型** | HIP / ROCm 7.1+ | CUDA |
| **价格** | ~$1,500 | — |

### 2.2 为什么选 R9700 而非 Instinct

| | R9700 | Instinct MI250X |
|---|:---:|:---:|
| **FP32 算力** | ~48 TFLOPS | 47.9 TFLOPS（相同） |
| **FP64 算力** | 0.76 TFLOPS | 47.9 TFLOPS |
| **价格** | ~$1,500 | ~$15,000+ |
| **部署** | 控制室工作站 | 专用机房 |

P-EFIT 使用 **FP32 单精度**（已在 EAST 验证足够）。射线追踪的 ODE 积分理论上需要 FP64，但通过自适应步长控制，FP32 在实时场景下可接受。R9700 的 FP32 性价比（算力/价格）是 Instinct 的 **10 倍**。

---

## 3. 计算任务一：GPU-EFIT 平衡重建

### 3.1 算法核心

基于 EAST 装置 P-EFIT（Huang et al., ASIPP, 2016-2020），核心是 GPU 并行 Grad-Shafranov 方程求解器：

```
P-EFIT 迭代流程（每次平衡重建 10-30 次 Picard 迭代）
═══════════════════════════════════════════════════════════

├─► 1. 电流密度拟合 (current_)         占比 <10%
├─► 2. 极向磁通计算 (pflux_)           占比 57-92% ← 最耗时
│      ├─ Green 函数边界条件             O(N³), 带宽密集
│      └─ G-S 方程求解（5 步）:
│           Step 1: Q^T × Ψ            矩阵乘 → FP16/FP32
│           Step 2: 转置                内存操作
│           Step 3: M 个三对角系统       前缀和并行
│           Step 4: 转置                内存操作
│           Step 5: Q × X              矩阵乘 → FP16/FP32
├─► 3. 磁面搜索 (steps_)               占比 <5%
└─► 4. 收敛检查
```

**关键创新**：用特征值分解（而非 FFT）将块三对角系统解耦为 M 个独立三对角系统，完美匹配 GPU 的大规模并行架构。

### 3.2 CUDA → HIP 移植

P-EFIT 原始代码为 CUDA，移植到 HIP 分两步：

**机械转换**（hipify 工具，覆盖 ~90%）：`cudaMalloc→hipMalloc`, `cudaMemcpy→hipMemcpy`，`__shared__`/`__syncthreads__`/`<<<grid,block>>>` 语法完全相同。

**RDNA 4 架构调优**（手动，关键差异）：

| 调优项 | TITAN X → R9700 变化 | 影响 |
|--------|---------------------|------|
| Tile Size | 16 → 32 | LDS 128KB 专用，矩阵乘效率翻倍 |
| Block/Grid | 适配 64 CU | 三对角 127 block → 2 轮完成（原 5 轮） |
| 循环展开 | 4× 展开 | 768KB VGPR 消除寄存器压力 |
| 内存访问 | 利用 Infinity Cache | Green 矩阵 ≤33MB 可全缓存 |

### 3.3 HIP Kernel 设计（三个核心 Kernel）

**Kernel 1: 特征分解矩阵乘法 (Step 1 & 5)**

```cpp
#define TILE_SIZE 32  // RDNA 4: 128KB LDS 支持更大 tile

__global__ void eigen_decomp_kernel(
    const float* __restrict__ Q, const float* __restrict__ Psi,
    float* __restrict__ Psi_prime, int M)
{
    __shared__ float tile_Q[TILE_SIZE][TILE_SIZE + 1];
    __shared__ float tile_Psi[TILE_SIZE][TILE_SIZE + 1];
    int row = blockIdx.y * TILE_SIZE + threadIdx.y;
    int col = blockIdx.x * TILE_SIZE + threadIdx.x;
    float sum = 0.0f;

    for (int t = 0; t < (M + TILE_SIZE - 1) / TILE_SIZE; t++) {
        int k_Q = t * TILE_SIZE + threadIdx.x;
        int k_Psi = t * TILE_SIZE + threadIdx.y;
        tile_Q[threadIdx.y][threadIdx.x] =
            (row < M && k_Q < M) ? Q[k_Q * M + row] : 0.0f;
        tile_Psi[threadIdx.y][threadIdx.x] =
            (k_Psi < M && col < M) ? Psi[k_Psi * M + col] : 0.0f;
        __syncthreads();
        #pragma unroll
        for (int k = 0; k < TILE_SIZE; k++)
            sum += tile_Q[threadIdx.y][k] * tile_Psi[k][threadIdx.x];
        __syncthreads();
    }
    if (row < M && col < M) Psi_prime[row * M + col] = sum;
}
```

**Kernel 2: 并行三对角求解 (Step 3)**

```cpp
__global__ void tridiag_solve_kernel(
    const float* __restrict__ a_coeff, const float* __restrict__ m_coeff,
    const float* __restrict__ rhs, float* __restrict__ x, int M)
{
    int j = blockIdx.x;  // 粗粒度: 每个 block 解一个独立系统
    if (j >= M) return;
    extern __shared__ float sdata[];
    float* s_d = sdata; float* s_x = sdata + M;
    int tid = threadIdx.x;
    if (tid < M) s_d[tid] = rhs[tid * M + j];
    __syncthreads();
    // 前缀和: O(M) 串行 → O(log₂M) 并行
    for (int stride = 1; stride < M; stride <<= 1) {
        if (tid >= stride && tid < M)
            s_d[tid] += m_coeff[tid * M + (tid - stride)] * s_d[tid - stride];
        __syncthreads();
    }
    if (tid == M - 1) s_x[tid] = s_d[tid] * a_coeff[tid];
    __syncthreads();
    for (int stride = M >> 1; stride >= 1; stride >>= 1) {
        if (tid < M - stride)
            s_x[tid] = a_coeff[tid] * (s_d[tid] - s_x[idx + stride]);
        __syncthreads();
    }
    if (tid < M) x[tid * M + j] = s_x[tid];
}
// 129×129: 127 blocks / 64 CU = 2 轮完成 (TITAN X 需 5 轮)
```

**Kernel 3: Green 函数边界条件**

```cpp
__global__ void green_boundary_kernel(
    const float* __restrict__ G_matrix, const float* __restrict__ J_plasma,
    float* __restrict__ psi_boundary, int N_bnd, int N_inner)
{
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= N_bnd) return;
    float sum = 0.0f;
    const float* G_row = G_matrix + i * N_inner;
    for (int j = 0; j < N_inner; j += 4) {  // 4× 展开, VGPR 充裕
        sum += G_row[j] * J_plasma[j] + G_row[j+1] * J_plasma[j+1]
             + G_row[j+2] * J_plasma[j+2] + G_row[j+3] * J_plasma[j+3];
    }
    psi_boundary[i] = sum;
}
// 129×129: G矩阵 33MB ⊂ 64MB Infinity Cache → 有效带宽 2-4 TB/s
```

### 3.4 Infinity Cache：EFIT 性能的决定性因素

| 网格 | Green 矩阵大小 | 能否缓存于 64MB Infinity Cache | pflux_ 加速倍数 |
|------|------------|:---:|:---:|
| 65×65 | ~4 MB | ✓ 完全 | ~4.3× |
| 129×129 | ~33 MB | ✓ 大部分 | ~3.9× |
| 257×257 | ~266 MB | ✗ | ~1.5× (仅靠 FP32+带宽) |

### 3.5 混合精度策略

R9700 的 FP16 矩阵算力达 191 TFLOPS（FP32 的 4 倍）。EFIT 迭代的前 80% 使用 FP16（收敛过程自动纠正），最后 20% + 三对角求解使用 FP32。在纯 FP32 基础上额外加速 ~2.5×。

### 3.6 AI 辅助加速

用历史放电数据训练神经网络预测 EFIT 初始值，使 Picard 迭代次数从 10-15 降至 3-5。NN 推理 ~0.1ms（R9700 AI 加速器，INT8 量化），净节省 ~0.8ms。

---

## 4. 计算任务二：GPU 射线追踪

### 4.1 计算任务定义

ECRH 系统接收 PCS 输出的 ρ_target 后，需要求解最优 Launcher 角度 (θ,φ)，使微波束在等离子体中传播后沉积在目标位置。这需要求解 Hamilton 射线方程组（ODE）：

```
dr/dτ = -∂H/∂k / (∂H/∂ω)    dk/dτ = +∂H/∂r / (∂H/∂ω)

色散关系 H 依赖: ne(R,Z), Te(R,Z), B(R,Z) → 来自 GPU-EFIT 输出
每条射线: ~10⁴ ODE 积分步 × ~10⁶ 浮点运算
```

### 4.2 业界现状与瓶颈

| 装置 | 方案 | 射线追踪周期 | 能否实时优化角度 |
|------|------|:---:|:---:|
| ASDEX Upgrade | rt-TORBEAM (CPU 多线程) | 15-20 ms / 12束 | ✗ 仅正向计算 |
| DIII-D | rt-TORBEAM + ML 剖面重建 | < 20 ms / 6面镜 | ✗ |
| ITER (计划) | rt-TORBEAM 移植 | 估计 15-20 ms / 24束 | ✗ |

**CPU 的核心限制**：多线程只能并行不同束（12 束 = 12 线程），但无法并行搜索不同候选角度。搜索 1000 个候选角度需要 1000× 单束时间 = ~15 秒，完全不可实时。

### 4.3 GPU 加速的天然匹配

射线追踪存在 **两层并行性**，GPU 可同时利用：

| 并行层次 | 并行度 | CPU 利用 | GPU 利用 |
|---------|:---:|:---:|:---:|
| 层次 1: 束间并行（12 束独立） | 12 | ✓ (多线程) | ✓ |
| 层次 2: 角度搜索并行（1000 候选角度独立） | 1000 | ✗ | **✓** |
| **组合** | **12,000** | 12 | **12,000** |

### 4.4 GPU 射线追踪软件架构

```
GPU 射线追踪服务 (libECRT-GPU, HIP/ROCm)
═══════════════════════════════════════════════════════

Host (C++):
  接收 ne, Te, B 剖面 (来自 GPU-EFIT) + ρ_target (来自 PCS)
  → 生成候选角度网格 → 调度 GPU kernel → 收集最优解

Device (HIP Kernels):
  Kernel ray_trace:    每线程追踪一条射线 (一个角度一个束)
                       ODE 积分 ~10⁴ 步, 输出 ρ_dep
  Kernel optimize:     并行归约, 找 min|ρ_dep - ρ_target|

关键优化:
  • 等离子体剖面缓存于 LDS/Infinity Cache
  • 自适应角度网格: 粗搜 100 → 细搜 100 (精度=均匀搜索 10000)
  • 异步流水线: 当前周期计算 ‖ 下周期数据传输
```

### 4.5 降级与容错

GPU 是性能增强层。故障时自动切换到 CPU 预计算查找表（当前业界标准做法），不影响系统安全。

---

## 5. 全链条流水线设计

### 5.1 同一 GPU 上的流水线执行

```
R9700 上 GPU-EFIT + GPU 射线追踪的流水线
═══════════════════════════════════════════════════════════

时间 →  0       0.6ms     1.0ms     1.5ms
        │        │         │         │
Stream 1 (EFIT):
        [ GPU-EFIT 129×129 (混合精度+AI) ]
        输出: ψ(R,Z), ne(ρ), Te(ρ), B(R,Z), ρ_target

Stream 2 (Ray Tracing):
                 [ GPU 射线追踪 12束×100角度 ]
                 输入: EFIT 第 5 次迭代中间结果
                 输出: (θ_opt, φ_opt) → ECRH Launcher

合并:                               [角度指令 → ECRH]

总延迟: ~1.5 ms (两个计算部分重叠)
显存: EFIT ~136MB + 射线追踪 ~100MB = 236MB << 32GB
```

### 5.2 端到端时间对比

```
控制链端到端延迟对比
═══════════════════════════════════════════════════════════

当前业界最佳 (全 CPU):
  诊断→PCS(EFIT): 5-10 ms → 射线追踪: 15-20 ms → 执行: 1 ms
  总计: ~21-31 ms

R9700 方案 (单 GPU 流水线):
  诊断→GPU-EFIT: 0.6-1.5 ms → 射线追踪: 重叠 → 执行: 1 ms
  总计: ~1.7-2.6 ms

加速比: ~10-15×
成本: ~$1,500 (一块 GPU 卡)
```

---

## 6. 性能估算汇总

### 6.1 GPU-EFIT 性能

| 网格 | CPU 单核 | TITAN X (P-EFIT) | **R9700 (FP32)** | **R9700 (混合精度+AI)** |
|------|---------|-----------------|-----------------|----------------------|
| 65×65 | 4 ms | ~3 ms | ~0.8 ms | **~0.35 ms** |
| 129×129 | 24 ms | ~5.5 ms | ~1.5 ms | **~0.6 ms** |
| 257×257 | 170 ms | 不可用 | ~21 ms | **~9 ms** |
| 513×513 | 1,150 ms | 不可用 | ~175 ms | **~75 ms** |

### 6.2 GPU 射线追踪性能

| 指标 | 当前业界 (CPU rt-TORBEAM) | **R9700 方案** | 提升 |
|------|-------------------------|---------------|:---:|
| 12 束正向追踪 | 15-20 ms | **~0.3 ms** | ~50× |
| 全局角度优化 (12束×1000角度) | 不可能 (~15 秒) | **< 0.5 ms** | ∞ |
| ECRH 内部总延迟 | 16-21 ms | **< 1.5 ms** | ~12× |

### 6.3 全链条性能

| 指标 | 当前业界 | R9700 方案 | 提升 |
|------|---------|-----------|:---:|
| PCS 平衡重建 (129×129) | 5-10 ms | **0.6 ms** | ~10× |
| ECRH 射线追踪 + 角度优化 | 15-20 ms | **0.5 ms** (流水线重叠) | ~35× |
| **端到端计算延迟** | **~25 ms** | **~1.5-2 ms** | **~15×** |
| 硬件成本 | — | **~$1,500** | — |

### 6.4 ECRH 获得的新能力

| 能力 | 之前 | GPU 后 |
|------|:---:|:---:|
| 实时全局角度优化 | ✗ (查找表) | ✓ (每周期实时求解) |
| 等离子体变化自适应 | ✗ (离线表可能过时) | ✓ (每周期重新计算) |
| 多目标联合优化 (精度+效率+功率) | ✗ | ✓ |
| 输入不确定性鲁棒优化 | ✗ | ✓ |

---

## 7. 实施路线

| 阶段 | 时间 | 工作内容 |
|------|------|---------|
| **Phase 0** | 1 月 | ROCm/HIP 环境 + R9700 硬件到位 |
| **Phase 1** | 3 月 | G-S 求解器 5 步 HIP kernel; 65/129 网格验证 |
| **Phase 2** | 3 月 | 完整 GPU-EFIT + 257 网格; 射线追踪 HIP kernel |
| **Phase 3** | 2 月 | 混合精度 (FP16 矩阵乘) + AI 初始化 (NN 训练) |
| **Phase 4** | 3 月 | EFIT→射线追踪流水线; 与 BEST PCS/ECRH 集成; 端到端测试 |
| **Phase 5** | 运行后 | 装置实际放电验证; 迭代优化 |

**总计：~12 个月**（Phase 0-4）

### 风险与应对

| 风险 | 应对 |
|------|------|
| P-EFIT 源码不可获取 | 基于 4 篇公开论文（含伪代码）重新实现 |
| RDNA 4 ROCm 成熟度 | R9700 已确认 ROCm 7.1+; 与 AMD 专业支持合作 |
| FP32 精度不足 | P-EFIT 已在 EAST 验证 FP32 够用; 射线追踪用自适应步长补偿 |
| GPU 故障 | 自动降级到 CPU 查找表 (当前业界标准), 不影响安全 |

---

## 参考文献

1. Huang Y. et al., "Implementation of GPU parallel equilibrium reconstruction for plasma control in EAST," *Fusion Eng. Des.*, 112, 2016.
2. Huang Y. et al., "Fast parallel Grad–Shafranov solver for real-time equilibrium reconstruction in EAST tokamak using GPU," *Chinese Physics B*, 26(8), 2017.
3. Huang Y. et al., "Improvement of GPU parallel real-time equilibrium reconstruction for plasma control," *Fusion Eng. Des.*, 128, 2018.
4. Huang Y. et al., "GPU-optimized fast plasma equilibrium reconstruction in fine grids," *Nuclear Fusion*, 60, 2020.
5. Antepara O. et al., "Performance-Portable GPU Acceleration of EFIT," SC '23 Workshops, 2023.
6. E. Poli et al., "Real-time beam tracing for control of EC wave deposition," *Fusion Eng. Des.*, 2015.
7. "Parallelized Real-time Physics Codes for Plasma Control on DIII-D," arXiv:2511.11964, 2025.
8. "Fast physics-based launcher optimization for ECCD," *Plasma Phys. Control. Fusion*, 2025.
9. AMD, "Radeon AI PRO R9700 Quick Reference Guide," 2025.
10. AMD, "RDNA 4 Instruction Set Architecture," 2025.

---

*本方案在一块 AMD Radeon AI PRO R9700 GPU (~$1,500) 上同时部署 GPU-EFIT 平衡重建和 GPU 射线追踪，通过 HIP 流水线将 BEST 控制链的端到端计算延迟从 ~25ms 压缩到 ~1.5-2ms (加速 ~15×)。GPU-EFIT 实现 129×129 网格亚毫秒重建 (比 EAST P-EFIT 快 9×, 比 CPU 快 40×)；GPU 射线追踪首次实现实时全局角度优化 (比 CPU rt-TORBEAM 快 50×)。这不仅是 NTM 抑制的使能技术，更是 BEST 所有实时等离子体控制功能的通用计算基础设施。*
